{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('train.csv', encoding='big5')\n",
    "row_count = train_set.shape[0]\n",
    "vectors = []\n",
    "for i in range(18):\n",
    "    vectors.append(train_set.iloc[i])\n",
    "for i in range(18, row_count):\n",
    "    vectors[i % 18] = pd.concat([vectors[i % 18], train_set.iloc[i]])\n",
    "\n",
    "series_dict = {}\n",
    "index = 0\n",
    "for row in vectors:\n",
    "    series_dict[index] = row\n",
    "    index += 1\n",
    "extracted_train_set = pd.DataFrame(series_dict)\n",
    "extracted_train_set = extracted_train_set.T\n",
    "# extracted_train_set = extracted_train_set.drop(['日期', '測站', '測項'], axis=1)\n",
    "extracted_train_set = extracted_train_set.replace('NR', 0.0)\n",
    "# extracted_train_set.to_csv('extracted_train.csv')\n",
    "list_x = []\n",
    "list_y = []\n",
    "i = 0\n",
    "j = 0\n",
    "while i < extracted_train_set.shape[1]:\n",
    "    mouth_set = extracted_train_set.iloc[:, i:27 * 20 * (j + 1)]\n",
    "    mouth_set = mouth_set.drop(['日期', '測站', '測項'], axis=1)\n",
    "    array = np.array(mouth_set).astype(np.float32)\n",
    "    for k in range(array.shape[1]):\n",
    "        if k + 9 >= array.shape[1]:\n",
    "            break\n",
    "        mat = array[:, k:k + 9]\n",
    "        label = array[9, k + 9]\n",
    "        list_x.append(mat.ravel())\n",
    "        list_y.append(label)\n",
    "    i += 27 * 20\n",
    "    j += 1\n",
    "train_x = np.array(list_x)\n",
    "train_y = np.array(list_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.40e+01, 1.40e+01, 1.40e+01, 1.30e+01, 1.20e+01, 1.20e+01,\n",
       "       1.20e+01, 1.20e+01, 1.50e+01, 1.80e+00, 1.80e+00, 1.80e+00,\n",
       "       1.80e+00, 1.80e+00, 1.80e+00, 1.80e+00, 1.80e+00, 1.80e+00,\n",
       "       5.10e-01, 4.10e-01, 3.90e-01, 3.70e-01, 3.50e-01, 3.00e-01,\n",
       "       3.70e-01, 4.70e-01, 7.80e-01, 2.00e-01, 1.50e-01, 1.30e-01,\n",
       "       1.20e-01, 1.10e-01, 6.00e-02, 1.00e-01, 1.30e-01, 2.60e-01,\n",
       "       9.00e-01, 6.00e-01, 5.00e-01, 1.70e+00, 1.80e+00, 1.50e+00,\n",
       "       1.90e+00, 2.20e+00, 6.60e+00, 1.60e+01, 9.20e+00, 8.20e+00,\n",
       "       6.90e+00, 6.80e+00, 3.80e+00, 6.90e+00, 7.80e+00, 1.50e+01,\n",
       "       1.70e+01, 9.80e+00, 8.70e+00, 8.60e+00, 8.50e+00, 5.30e+00,\n",
       "       8.80e+00, 9.90e+00, 2.20e+01, 1.60e+01, 3.00e+01, 2.70e+01,\n",
       "       2.30e+01, 2.40e+01, 2.80e+01, 2.40e+01, 2.20e+01, 2.10e+01,\n",
       "       5.60e+01, 5.00e+01, 4.80e+01, 3.50e+01, 2.50e+01, 1.20e+01,\n",
       "       4.00e+00, 2.00e+00, 1.10e+01, 2.60e+01, 3.90e+01, 3.60e+01,\n",
       "       3.50e+01, 3.10e+01, 2.80e+01, 2.50e+01, 2.00e+01, 1.90e+01,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 7.70e+01, 6.80e+01, 6.70e+01,\n",
       "       7.40e+01, 7.20e+01, 7.30e+01, 7.40e+01, 7.30e+01, 6.60e+01,\n",
       "       1.80e+00, 2.00e+00, 1.70e+00, 1.60e+00, 1.90e+00, 1.40e+00,\n",
       "       1.50e+00, 1.60e+00, 5.10e+00, 2.00e+00, 2.00e+00, 2.00e+00,\n",
       "       1.90e+00, 1.90e+00, 1.80e+00, 1.90e+00, 1.90e+00, 2.10e+00,\n",
       "       3.70e+01, 8.00e+01, 5.70e+01, 7.60e+01, 1.10e+02, 1.06e+02,\n",
       "       1.01e+02, 1.04e+02, 1.24e+02, 3.50e+01, 7.90e+01, 2.40e+00,\n",
       "       5.50e+01, 9.40e+01, 1.16e+02, 1.06e+02, 9.40e+01, 2.32e+02,\n",
       "       1.40e+00, 1.80e+00, 1.00e+00, 6.00e-01, 1.70e+00, 2.50e+00,\n",
       "       2.50e+00, 2.00e+00, 6.00e-01, 5.00e-01, 9.00e-01, 6.00e-01,\n",
       "       3.00e-01, 6.00e-01, 1.90e+00, 2.00e+00, 2.00e+00, 5.00e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-316-d8d6fd08cc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-316-d8d6fd08cc92>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_y_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-316-d8d6fd08cc92>\u001b[0m in \u001b[0;36msgd_op\u001b[0;34m(loss, learning_rate)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msgd_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       raise RuntimeError(\n\u001b[0;32m--> 481\u001b[0;31m           \u001b[0;34m\"`loss` passed to Optimizer.compute_gradients should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m           \"be a function when eager execution is enabled.\")\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "# x = tf.placeholder(tf.float32, [162])\n",
    "w = tf.Variable(tf.zeros([162]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# y = b + np.dot(w, x)\n",
    "\n",
    "# lost = tf.reduce_mean(tf.square(y_ - y))\n",
    "\n",
    "def get_y_predict(train_x):\n",
    "    y = []\n",
    "    for i in range(train_x.shape[0]):\n",
    "        x = tf.Variable(train_x[i])\n",
    "        xs = tf.reshape(x, [162,1])\n",
    "        ws = tf.reshape(w, [162,1])\n",
    "        y.append(b + tf.matmul(ws, xs, transpose_a=True))\n",
    "    return tf.Variable(y)\n",
    "\n",
    "def get_loss(y_true, y_predict):\n",
    "    return tf.reduce_mean(tf.reduce_sum((tf.square(y_true - y_predict))))\n",
    "\n",
    "def sgd_op(loss, learning_rate):\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    return train_op\n",
    "\n",
    "def train():\n",
    "    y_true = tf.Variable(train_y)\n",
    "    y_predict = get_y_predict(train_x)\n",
    "    loss = get_loss(y_true, y_predict)\n",
    "    train_op = sgd_op(loss, 0.00001)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(20000):\n",
    "            sess.run([train_op])\n",
    "            \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(162,) dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(train_x[0].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(162,) dtype=float64, numpy=\n",
       "array([1.40e+01, 1.40e+01, 1.40e+01, 1.30e+01, 1.20e+01, 1.20e+01,\n",
       "       1.20e+01, 1.20e+01, 1.50e+01, 1.80e+00, 1.80e+00, 1.80e+00,\n",
       "       1.80e+00, 1.80e+00, 1.80e+00, 1.80e+00, 1.80e+00, 1.80e+00,\n",
       "       5.10e-01, 4.10e-01, 3.90e-01, 3.70e-01, 3.50e-01, 3.00e-01,\n",
       "       3.70e-01, 4.70e-01, 7.80e-01, 2.00e-01, 1.50e-01, 1.30e-01,\n",
       "       1.20e-01, 1.10e-01, 6.00e-02, 1.00e-01, 1.30e-01, 2.60e-01,\n",
       "       9.00e-01, 6.00e-01, 5.00e-01, 1.70e+00, 1.80e+00, 1.50e+00,\n",
       "       1.90e+00, 2.20e+00, 6.60e+00, 1.60e+01, 9.20e+00, 8.20e+00,\n",
       "       6.90e+00, 6.80e+00, 3.80e+00, 6.90e+00, 7.80e+00, 1.50e+01,\n",
       "       1.70e+01, 9.80e+00, 8.70e+00, 8.60e+00, 8.50e+00, 5.30e+00,\n",
       "       8.80e+00, 9.90e+00, 2.20e+01, 1.60e+01, 3.00e+01, 2.70e+01,\n",
       "       2.30e+01, 2.40e+01, 2.80e+01, 2.40e+01, 2.20e+01, 2.10e+01,\n",
       "       5.60e+01, 5.00e+01, 4.80e+01, 3.50e+01, 2.50e+01, 1.20e+01,\n",
       "       4.00e+00, 2.00e+00, 1.10e+01, 2.60e+01, 3.90e+01, 3.60e+01,\n",
       "       3.50e+01, 3.10e+01, 2.80e+01, 2.50e+01, 2.00e+01, 1.90e+01,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "       0.00e+00, 0.00e+00, 0.00e+00, 7.70e+01, 6.80e+01, 6.70e+01,\n",
       "       7.40e+01, 7.20e+01, 7.30e+01, 7.40e+01, 7.30e+01, 6.60e+01,\n",
       "       1.80e+00, 2.00e+00, 1.70e+00, 1.60e+00, 1.90e+00, 1.40e+00,\n",
       "       1.50e+00, 1.60e+00, 5.10e+00, 2.00e+00, 2.00e+00, 2.00e+00,\n",
       "       1.90e+00, 1.90e+00, 1.80e+00, 1.90e+00, 1.90e+00, 2.10e+00,\n",
       "       3.70e+01, 8.00e+01, 5.70e+01, 7.60e+01, 1.10e+02, 1.06e+02,\n",
       "       1.01e+02, 1.04e+02, 1.24e+02, 3.50e+01, 7.90e+01, 2.40e+00,\n",
       "       5.50e+01, 9.40e+01, 1.16e+02, 1.06e+02, 9.40e+01, 2.32e+02,\n",
       "       1.40e+00, 1.80e+00, 1.00e+00, 6.00e-01, 1.70e+00, 2.50e+00,\n",
       "       2.50e+00, 2.00e+00, 6.00e-01, 5.00e-01, 9.00e-01, 6.00e-01,\n",
       "       3.00e-01, 6.00e-01, 1.90e+00, 2.00e+00, 2.00e+00, 5.00e-01])>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
